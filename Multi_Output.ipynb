{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localhost\n",
    "# http://localhost:4040/ \n",
    "\n",
    "# Packages\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|   name|gender|salary|\n",
      "+-------+------+------+\n",
      "|  James|     M| 60000|\n",
      "|Michael|     M| 70000|\n",
      "| Robert|  null|400000|\n",
      "|  Maria|     F|500000|\n",
      "|    Jen|      |  null|\n",
      "+-------+------+------+\n",
      "\n",
      "+---------+----------+--------+----------+\n",
      "|firstname|middlename|lastname|       dob|\n",
      "+---------+----------+--------+----------+\n",
      "|    James|          |   Smith|1991-04-01|\n",
      "|  Michael|      Rose|        |2000-05-19|\n",
      "|   Robert|          |Williams|1978-09-05|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|\n",
      "+---------+----------+--------+----------+\n",
      "\n",
      "+--------------------+------------------+-----+------+-------+\n",
      "|                name|         languages|state|gender|gender2|\n",
      "+--------------------+------------------+-----+------+-------+\n",
      "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|   Male|\n",
      "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F| Female|\n",
      "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|   Male|\n",
      "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M| Female|\n",
      "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|   Male|\n",
      "|{Mike, Mary, Will...|      [Python, VB]|   OH|     M| Female|\n",
      "+--------------------+------------------+-----+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when()\n",
    "data = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n",
    "        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n",
    "        (\"Jen\",\"\",None)]\n",
    "columns = [\"name\",\"gender\",\"salary\"]\n",
    "df_when = spark.createDataFrame(data = data, schema = columns)\n",
    "df_when.show()\n",
    "\n",
    "\n",
    "# split()\n",
    "data=data = [('James','','Smith','1991-04-01'),\n",
    "  ('Michael','Rose','','2000-05-19'),\n",
    "  ('Robert','','Williams','1978-09-05'),\n",
    "  ('Maria','Anne','Jones','1967-12-01'),\n",
    "  ('Jen','Mary','Brown','1980-02-17')]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\"]\n",
    "df_split = spark.createDataFrame(data,columns)\n",
    "df_split.show()\n",
    "\n",
    "\n",
    "# df_filter\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\",\"Male\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\",\"Female\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\",\"Male\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\",\"Female\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\",\"Male\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\",\"Female\")\n",
    " ]\n",
    "        \n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True),\n",
    "     StructField('gender2', StringType(), True)\n",
    " ])\n",
    "\n",
    "df_filtering = spark.createDataFrame(data = data, schema = schema)\n",
    "df_filtering.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMS = []\n",
    "\n",
    "DATASETS = {\n",
    "    \"WHENING\"   : df_when,\n",
    "    \"SPLITTING\" : df_split,\n",
    "    \"FILTERING\" : df_filtering,\n",
    "    }\n",
    "\n",
    "for table_name, table_location in list(DATASETS.items()):\n",
    "    def multi_output(Input_table, table_name=table_name):\n",
    "        if table_name==\"WHENING\":\n",
    "            output_table = Input_table.drop(\"salary\")\n",
    "        \n",
    "        elif table_name==\"SPLITTING\":\n",
    "            output_table== Input_table.drop(\"dob\")\n",
    "        \n",
    "        elif table_name==\"FILTERING\":\n",
    "            output_table = Input_table.drop(\"gender2\")\n",
    "        \n",
    "        return output_table\n",
    "    \n",
    "    TRANSFORMS.append(multi_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function multi_output at 0x7fee51b09dc0>\n"
     ]
    }
   ],
   "source": [
    "print(TRANSFORMS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multi_output(Input_table, table_name='WHENING')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Sparky').getOrCreate()\n",
    "\n",
    "\n",
    "# Create the initial dataframe\n",
    "data = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n",
    "        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n",
    "        (\"Jen\",\"\",None)]\n",
    "columns = [\"name\",\"gender\",\"salary\"]\n",
    "df_when = spark.createDataFrame(data = data, schema = columns)\n",
    "\n",
    "# Create three identical datasets\n",
    "df_1 = df_when\n",
    "df_2 = df_when\n",
    "df_3 = df_when\n",
    "\n",
    "\n",
    "TRANSFORMS = []\n",
    "\n",
    "DATASETS = {\n",
    "    \"ONE\"   : df_1,\n",
    "    \"TWO\" : df_2,\n",
    "    \"THREE\" : df_3,\n",
    "    }\n",
    "\n",
    "for table_name, table_location in list(DATASETS.items()):\n",
    "    def multi_output(Input_table, table_name=table_name):\n",
    "        if table_name==\"ONE\":\n",
    "            output_table = Input_table.drop(\"name\")\n",
    "        \n",
    "        elif table_name==\"TWO\":\n",
    "            output_table== Input_table.drop(\"gender\")\n",
    "        \n",
    "        elif table_name==\"THREE\":\n",
    "            output_table = Input_table.drop(\"salary\")\n",
    "        \n",
    "        return output_table\n",
    "    \n",
    "    TRANSFORMS.append(multi_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multi_output(Input_table, table_name='ONE')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d105ada02192d0bbdad0d4b7f9e51b851ebd5be727b9bab0a9679568b88653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('pyspark_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
