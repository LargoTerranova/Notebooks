{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Import Packages\n",
    "####################################################################################\n",
    "# Localhost\n",
    "# http://localhost:4040/ \n",
    "\n",
    "# Packages\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|       A/5 21171|   7.25|  nan|       S|\n",
      "|          2|       1|     1|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|female|26.0|    0|    0|STON/O2. 3101282|  7.925|  nan|       S|\n",
      "|          4|       1|     1|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|          373450|   8.05|  nan|       S|\n",
      "|          6|       0|     3|  male| NaN|    0|    0|          330877| 8.4583|  nan|       Q|\n",
      "|          7|       0|     1|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|  male| 2.0|    3|    1|          349909| 21.075|  nan|       S|\n",
      "|          9|       1|     3|female|27.0|    0|    2|          347742|11.1333|  nan|       S|\n",
      "|         10|       1|     2|female|14.0|    1|    0|          237736|30.0708|  nan|       C|\n",
      "|         11|       1|     3|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|  male|20.0|    0|    0|       A/5. 2151|   8.05|  nan|       S|\n",
      "|         14|       0|     3|  male|39.0|    1|    5|          347082| 31.275|  nan|       S|\n",
      "|         15|       0|     3|female|14.0|    0|    0|          350406| 7.8542|  nan|       S|\n",
      "|         16|       1|     2|female|55.0|    0|    0|          248706|   16.0|  nan|       S|\n",
      "|         17|       0|     3|  male| 2.0|    4|    1|          382652| 29.125|  nan|       Q|\n",
      "|         18|       1|     2|  male| NaN|    0|    0|          244373|   13.0|  nan|       S|\n",
      "|         19|       0|     3|female|31.0|    1|    0|          345763|   18.0|  nan|       S|\n",
      "|         20|       1|     3|female| NaN|    0|    0|            2649|  7.225|  nan|       C|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"/Users/largo/Google Drive/DS/Python/5_Importing_Data_1/Data/titanic_sub.csv\", sep=\",\", header=0)\n",
    "titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]] = titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]].astype(str)\n",
    "titanic = spark.createDataFrame(titanic)\n",
    "titanic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(PassengerId,LongType,true),StructField(Survived,LongType,true),StructField(Pclass,LongType,true),StructField(Sex,StringType,true),StructField(Age,DoubleType,true),StructField(SibSp,LongType,true),StructField(Parch,LongType,true),StructField(Ticket,StringType,true),StructField(Fare,DoubleType,true),StructField(Cabin,StringType,true),StructField(Embarked,StringType,true)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+\n",
      "|Survived_Y|Pclass_Y|Sex_Y |Age_Y|Parch_Y|Ticket_Y        |Fare_Y           |Cabin_Y|Embarked_Y|Class_Y  |Parch_New_Y|\n",
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+\n",
      "|0         |3       |MALE  |22.0 |0      |A/5 21171       |725.0            |nan    |S         |Prol     |[666, 777] |\n",
      "|1         |1       |FEMALE|38.0 |0      |PC 17599        |7128.33          |C85    |C         |Burgeous |[666, 777] |\n",
      "|1         |3       |FEMALE|26.0 |0      |STON/O2. 3101282|792.5            |nan    |S         |Prol     |[666, 777] |\n",
      "|1         |1       |FEMALE|35.0 |0      |113803          |5310.0           |C123   |S         |Burgeous |[666, 777] |\n",
      "|0         |3       |MALE  |35.0 |0      |373450          |805.0000000000001|nan    |S         |Prol     |[666, 777] |\n",
      "|0         |3       |MALE  |NaN  |0      |330877          |845.8299999999999|nan    |Q         |Prol     |[666, 777] |\n",
      "|0         |1       |MALE  |54.0 |0      |17463           |5186.25          |E46    |S         |Burgeous |[666, 777] |\n",
      "|0         |3       |MALE  |2.0  |1      |349909          |2107.5           |nan    |S         |Prol     |null       |\n",
      "|1         |3       |FEMALE|27.0 |2      |347742          |1113.33          |nan    |S         |Prol     |null       |\n",
      "|1         |2       |FEMALE|14.0 |0      |237736          |3007.08          |nan    |C         |Ambitious|[666, 777] |\n",
      "|1         |3       |FEMALE|4.0  |1      |PP 9549         |1670.0           |G6     |S         |Prol     |null       |\n",
      "|1         |1       |FEMALE|58.0 |0      |113783          |2655.0           |C103   |S         |Burgeous |[666, 777] |\n",
      "|0         |3       |MALE  |20.0 |0      |A/5. 2151       |805.0000000000001|nan    |S         |Prol     |[666, 777] |\n",
      "|0         |3       |MALE  |39.0 |5      |347082          |3127.5           |nan    |S         |Prol     |null       |\n",
      "|0         |3       |FEMALE|14.0 |0      |350406          |785.42           |nan    |S         |Prol     |[666, 777] |\n",
      "|1         |2       |FEMALE|55.0 |0      |248706          |1600.0           |nan    |S         |Ambitious|[666, 777] |\n",
      "|0         |3       |MALE  |2.0  |1      |382652          |2912.5           |nan    |Q         |Prol     |null       |\n",
      "|1         |2       |MALE  |NaN  |0      |244373          |1300.0           |nan    |S         |Ambitious|[666, 777] |\n",
      "|0         |3       |FEMALE|31.0 |0      |345763          |1800.0           |nan    |S         |Prol     |[666, 777] |\n",
      "|1         |3       |FEMALE|NaN  |0      |2649            |722.5            |nan    |C         |Prol     |[666, 777] |\n",
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remap the values in \"Pclass\" to Proletarian/Ambitious/Burgouise OK\n",
    "# Remap the values in \"Sex\" to 0/1 OK\n",
    "# Take log of \"Age\" OK\n",
    "# Clean the column \"Fare\" for inflation OK\n",
    "# Extract the number from the column \"Ticket\"\n",
    "# Fill in the missing values in the Cabin column\n",
    "from pyspark.sql.types import StringType, BooleanType, DateType\n",
    "\n",
    "def return_function(data, prefix, gender):\n",
    "    df = data\n",
    "    to_drop = [\"PassengerId\", \"SibSp\"]\n",
    "    df = df.drop(*to_drop)\n",
    "    df = df.withColumn(\"Class\",  when(df.Pclass == 3, \"Prol\").when(df.Pclass == 2, \"Ambitious\").when(df.Pclass == 1, \"Burgeous\"))\n",
    "    df = df.withColumn(\"Sex\", when(df.Sex==\"male\", \"MALE\").when(df.Sex==\"female\", \"FEMALE\"))\n",
    "    df = df.withColumn(\"Fare\", df.Fare*100)\n",
    "    df = df.withColumn(\"Parch_New\", F.when(F.col(\"Parch\")==0, F.array(F.lit('666'))))\n",
    "    df = df.withColumn(\"Parch_New\", F.when(F.col(\"Parch\")==0, F.array(F.lit(\"666\"), F.lit(\"777\"))))\n",
    "\n",
    "\n",
    "    # Write a function, add a column, if Parch_New=666 then \"first\" otherwise \"second\"\n",
    "\n",
    "    # Dictionary Loop to recast DataTypes\n",
    "    column_types = {\n",
    "        \"StringType()\": [\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"],\n",
    "        \"IntegerType()\": [\"Pclass\", \"Age\", \"SibSp\", \"Parch\"],\n",
    "        \"BooleanTyp0()\": [\"Survived\"]\n",
    "        }\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column in column_types.items():\n",
    "            df = df.withColumn(\"item\", df.item.cast(\"key\"))\n",
    "\n",
    "    \"\"\"\n",
    "        for key, value in age_group.items():\n",
    "        if df.Age in value:\n",
    "            df = df[key] \n",
    "    \"\"\"\n",
    "\n",
    "    #df = df.withColumn(\"Survived\", df.Survived.cast(BooleanType()))\n",
    "    #df = df.withColumn(\"Sex\", df.Sex.cast(StringType()))\n",
    "    #df = df.withColumn(\"Age\", df.Age.cast(IntegerType()))\n",
    "\n",
    "\n",
    "\n",
    "    # Write a loop that recasts the column types\n",
    "    string_typo = [\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "    if string_typo in df.columns:\n",
    "        for i in string_typo:\n",
    "            df = df.withColumn(i, df.i.cast(\"String\"))    \n",
    "    \n",
    " \n",
    "\n",
    "    # This renames the columns\n",
    "    for name in df.columns:\n",
    "        if prefix not in df.columns:\n",
    "            df = df.withColumnRenamed(name, name + '_' + prefix)\n",
    "        else:\n",
    "            raise ValueError('The chosen prefix already appers in the dataframe.')\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "new_df = return_function(titanic, \"Y\", \"MALE\")\n",
    "new_df.show(truncate=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+-------------------+\n",
      "|Survived_Y|Pclass_Y| Sex_Y|Age_Y|Parch_Y|        Ticket_Y|           Fare_Y|Cabin_Y|Embarked_Y|  Class_Y|Parch_New_Y|            REMOVED|\n",
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+-------------------+\n",
      "|         0|       3|  MALE| 22.0|      0|       A/5 21171|            725.0|    nan|         S|     Prol| [666, 777]|       [A/5, 21171]|\n",
      "|         1|       1|FEMALE| 38.0|      0|        PC 17599|          7128.33|    C85|         C| Burgeous| [666, 777]|        [PC, 17599]|\n",
      "|         1|       3|FEMALE| 26.0|      0|STON/O2. 3101282|            792.5|    nan|         S|     Prol| [666, 777]|[STON/O2., 3101282]|\n",
      "|         1|       1|FEMALE| 35.0|      0|          113803|           5310.0|   C123|         S| Burgeous| [666, 777]|           [113803]|\n",
      "|         0|       3|  MALE| 35.0|      0|          373450|805.0000000000001|    nan|         S|     Prol| [666, 777]|           [373450]|\n",
      "|         0|       3|  MALE|  NaN|      0|          330877|845.8299999999999|    nan|         Q|     Prol| [666, 777]|           [330877]|\n",
      "|         0|       1|  MALE| 54.0|      0|           17463|          5186.25|    E46|         S| Burgeous| [666, 777]|            [17463]|\n",
      "|         0|       3|  MALE|  2.0|      1|          349909|           2107.5|    nan|         S|     Prol|       null|           [349909]|\n",
      "|         1|       3|FEMALE| 27.0|      2|          347742|          1113.33|    nan|         S|     Prol|       null|           [347742]|\n",
      "|         1|       2|FEMALE| 14.0|      0|          237736|          3007.08|    nan|         C|Ambitious| [666, 777]|           [237736]|\n",
      "|         1|       3|FEMALE|  4.0|      1|         PP 9549|           1670.0|     G6|         S|     Prol|       null|         [PP, 9549]|\n",
      "|         1|       1|FEMALE| 58.0|      0|          113783|           2655.0|   C103|         S| Burgeous| [666, 777]|           [113783]|\n",
      "|         0|       3|  MALE| 20.0|      0|       A/5. 2151|805.0000000000001|    nan|         S|     Prol| [666, 777]|       [A/5., 2151]|\n",
      "|         0|       3|  MALE| 39.0|      5|          347082|           3127.5|    nan|         S|     Prol|       null|           [347082]|\n",
      "|         0|       3|FEMALE| 14.0|      0|          350406|           785.42|    nan|         S|     Prol| [666, 777]|           [350406]|\n",
      "|         1|       2|FEMALE| 55.0|      0|          248706|           1600.0|    nan|         S|Ambitious| [666, 777]|           [248706]|\n",
      "|         0|       3|  MALE|  2.0|      1|          382652|           2912.5|    nan|         Q|     Prol|       null|           [382652]|\n",
      "|         1|       2|  MALE|  NaN|      0|          244373|           1300.0|    nan|         S|Ambitious| [666, 777]|           [244373]|\n",
      "|         0|       3|FEMALE| 31.0|      0|          345763|           1800.0|    nan|         S|     Prol| [666, 777]|           [345763]|\n",
      "|         1|       3|FEMALE|  NaN|      0|            2649|            722.5|    nan|         C|     Prol| [666, 777]|             [2649]|\n",
      "+----------+--------+------+-----+-------+----------------+-----------------+-------+----------+---------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Removing characters from array\n",
    "#######################################\n",
    "new_df_2 = new_df.withColumn(\"REMOVED\", F.split(new_df[\"Parch_New_Y\"], \" \"))\n",
    "new_df_2.show()\n",
    "#new_df_2 = new_df_2.withColumnRenamed(\"REMOVED\", F.regexp_replace(F.col(\"Parch_New_Y\"), \"[\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+------+-----+-----+--------+----+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|Ticket| Fare|Cabin|Embarked|RANK|\n",
      "+-----------+--------+------+------+----+-----+-----+------+-----+-----+--------+----+\n",
      "|        258|       1|     1|female|30.0|    0|    0|110152| 86.5|  B77|       S|   1|\n",
      "|        505|       1|     1|female|16.0|    0|    0|110152| 86.5|  B79|       S|   1|\n",
      "|        760|       1|     1|female|33.0|    0|    0|110152| 86.5|  B77|       S|   1|\n",
      "|        263|       0|     1|  male|52.0|    1|    1|110413|79.65|  E67|       S|   1|\n",
      "+-----------+--------+------+------+----+-----+-----+------+-----+-----+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Partitioning and selecting\n",
    "##################################################\n",
    "df =titanic\n",
    "window_sep = Window.partitionBy(\"SEX\").orderBy(\"Ticket\")\n",
    "new_df = df.withColumn(\"RANK\", F.rank().over(window_sep))\n",
    "new_df.filter(new_df[\"RANK\"]==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fdf7fa73359b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-fdf7fa73359b>\u001b[0m in \u001b[0;36mreturn_function\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mage_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"/Users/largo/Google Drive/DS/Python/5_Importing_Data_1/Data/titanic_sub.csv\", sep=\",\", header=0)\n",
    "titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]] = titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]].astype(str)\n",
    "titanic = titanic.iloc[0:4, :]\n",
    "\n",
    "def return_function(data):\n",
    "    # This does some random stuff\n",
    "    df = data\n",
    "\n",
    "    # Create age buckets\n",
    "    age_group = {\n",
    "        \"young\": range(0,25),\n",
    "        \"middleaged\": range(26,50),\n",
    "        \"old\": range(51,110)\n",
    "        }\n",
    "\n",
    "\n",
    "    for key, value in age_group.items():\n",
    "        if df.Age in value:\n",
    "            df = df[key]\n",
    "    \n",
    "    return df\n",
    "\n",
    "new_df = return_function(titanic)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "table = spark.createDataFrame(data=simpleData, schema=schema)\n",
    "\n",
    "def recasting_function(data):\n",
    "    df = data\n",
    "\n",
    "    column_types = {\n",
    "        \"StringType()\": [\"employee_name\", \"department\"],\n",
    "        \"IntegerType()\": [\"salary\"]\n",
    "        }\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column in column_types.items():\n",
    "            df = df.withColumn(item, df.item.cast(key))\n",
    "    \n",
    "    return df\n",
    "        \n",
    "\n",
    "result = recasting_function(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a sample dataframe\n",
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "table = spark.createDataFrame(data=simpleData, schema=schema)\n",
    "\n",
    "# This is the function which is supposed to change datatypes en bulk\n",
    "def recasting_function(data):\n",
    "    column_types = {\n",
    "        \"string\": [\"employee_name\", \"department\", \"salary\"]\n",
    "        }\n",
    "    for (k, v) in column_types.items():\n",
    "        for c in v:\n",
    "            if c in data.columns:\n",
    "                data = data.withColumn(c, data[c].cast(k))    \n",
    "    return data\n",
    "        \n",
    "# Here I apply it to my sample dataset\n",
    "result = recasting_function(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d105ada02192d0bbdad0d4b7f9e51b851ebd5be727b9bab0a9679568b88653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('pyspark_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
