{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Import Packages\n",
    "####################################################################################\n",
    "# Localhost\n",
    "# http://localhost:4040/ \n",
    "\n",
    "# Packages\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|       A/5 21171|   7.25|  nan|       S|\n",
      "|          2|       1|     1|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|female|26.0|    0|    0|STON/O2. 3101282|  7.925|  nan|       S|\n",
      "|          4|       1|     1|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|          373450|   8.05|  nan|       S|\n",
      "|          6|       0|     3|  male| NaN|    0|    0|          330877| 8.4583|  nan|       Q|\n",
      "|          7|       0|     1|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|  male| 2.0|    3|    1|          349909| 21.075|  nan|       S|\n",
      "|          9|       1|     3|female|27.0|    0|    2|          347742|11.1333|  nan|       S|\n",
      "|         10|       1|     2|female|14.0|    1|    0|          237736|30.0708|  nan|       C|\n",
      "|         11|       1|     3|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|  male|20.0|    0|    0|       A/5. 2151|   8.05|  nan|       S|\n",
      "|         14|       0|     3|  male|39.0|    1|    5|          347082| 31.275|  nan|       S|\n",
      "|         15|       0|     3|female|14.0|    0|    0|          350406| 7.8542|  nan|       S|\n",
      "|         16|       1|     2|female|55.0|    0|    0|          248706|   16.0|  nan|       S|\n",
      "|         17|       0|     3|  male| 2.0|    4|    1|          382652| 29.125|  nan|       Q|\n",
      "|         18|       1|     2|  male| NaN|    0|    0|          244373|   13.0|  nan|       S|\n",
      "|         19|       0|     3|female|31.0|    1|    0|          345763|   18.0|  nan|       S|\n",
      "|         20|       1|     3|female| NaN|    0|    0|            2649|  7.225|  nan|       C|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"/Users/largo/Google Drive/DS/Python/5_Importing_Data_1/Data/titanic_sub.csv\", sep=\",\", header=0)\n",
    "titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]] = titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]].astype(str)\n",
    "titanic = spark.createDataFrame(titanic)\n",
    "titanic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(PassengerId,LongType,true),StructField(Survived,LongType,true),StructField(Pclass,LongType,true),StructField(Sex,StringType,true),StructField(Age,DoubleType,true),StructField(SibSp,LongType,true),StructField(Parch,LongType,true),StructField(Ticket,StringType,true),StructField(Fare,DoubleType,true),StructField(Cabin,StringType,true),StructField(Embarked,StringType,true)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+\n",
      "|Survived|Pclass|Sex   |Age |Parch|Ticket          |Fare             |Cabin|Embarked|Class    |Parch_New |\n",
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+\n",
      "|0       |3     |MALE  |22.0|0    |A/5 21171       |725.0            |nan  |S       |Prol     |[666, 777]|\n",
      "|1       |1     |FEMALE|38.0|0    |PC 17599        |7128.33          |C85  |C       |Burgeous |[666, 777]|\n",
      "|1       |3     |FEMALE|26.0|0    |STON/O2. 3101282|792.5            |nan  |S       |Prol     |[666, 777]|\n",
      "|1       |1     |FEMALE|35.0|0    |113803          |5310.0           |C123 |S       |Burgeous |[666, 777]|\n",
      "|0       |3     |MALE  |35.0|0    |373450          |805.0000000000001|nan  |S       |Prol     |[666, 777]|\n",
      "|0       |3     |MALE  |NaN |0    |330877          |845.8299999999999|nan  |Q       |Prol     |[666, 777]|\n",
      "|0       |1     |MALE  |54.0|0    |17463           |5186.25          |E46  |S       |Burgeous |[666, 777]|\n",
      "|0       |3     |MALE  |2.0 |1    |349909          |2107.5           |nan  |S       |Prol     |null      |\n",
      "|1       |3     |FEMALE|27.0|2    |347742          |1113.33          |nan  |S       |Prol     |null      |\n",
      "|1       |2     |FEMALE|14.0|0    |237736          |3007.08          |nan  |C       |Ambitious|[666, 777]|\n",
      "|1       |3     |FEMALE|4.0 |1    |PP 9549         |1670.0           |G6   |S       |Prol     |null      |\n",
      "|1       |1     |FEMALE|58.0|0    |113783          |2655.0           |C103 |S       |Burgeous |[666, 777]|\n",
      "|0       |3     |MALE  |20.0|0    |A/5. 2151       |805.0000000000001|nan  |S       |Prol     |[666, 777]|\n",
      "|0       |3     |MALE  |39.0|5    |347082          |3127.5           |nan  |S       |Prol     |null      |\n",
      "|0       |3     |FEMALE|14.0|0    |350406          |785.42           |nan  |S       |Prol     |[666, 777]|\n",
      "|1       |2     |FEMALE|55.0|0    |248706          |1600.0           |nan  |S       |Ambitious|[666, 777]|\n",
      "|0       |3     |MALE  |2.0 |1    |382652          |2912.5           |nan  |Q       |Prol     |null      |\n",
      "|1       |2     |MALE  |NaN |0    |244373          |1300.0           |nan  |S       |Ambitious|[666, 777]|\n",
      "|0       |3     |FEMALE|31.0|0    |345763          |1800.0           |nan  |S       |Prol     |[666, 777]|\n",
      "|1       |3     |FEMALE|NaN |0    |2649            |722.5            |nan  |C       |Prol     |[666, 777]|\n",
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remap the values in \"Pclass\" to Proletarian/Ambitious/Burgouise OK\n",
    "# Remap the values in \"Sex\" to 0/1 OK\n",
    "# Take log of \"Age\" OK\n",
    "# Clean the column \"Fare\" for inflation OK\n",
    "# Extract the number from the column \"Ticket\"\n",
    "# Fill in the missing values in the Cabin column\n",
    "from utils import genderselector\n",
    "from pyspark.sql.types import StringType, BooleanType, DateType\n",
    "\n",
    "def return_function(data, prefix, gender):\n",
    "    df = data\n",
    "    to_drop = [\"PassengerId\", \"SibSp\"]\n",
    "    df = df.drop(*to_drop)\n",
    "    df = df.withColumn(\"Class\",  when(df.Pclass == 3, \"Prol\").when(df.Pclass == 2, \"Ambitious\").when(df.Pclass == 1, \"Burgeous\"))\n",
    "    df = df.withColumn(\"Sex\", when(df.Sex==\"male\", \"MALE\").when(df.Sex==\"female\", \"FEMALE\"))\n",
    "    df = df.withColumn(\"Fare\", df.Fare*100)\n",
    "    df = df.withColumn(\"Parch_New\", F.when(F.col(\"Parch\")==0, F.array(F.lit('666'))))\n",
    "    df = df.withColumn(\"Parch_New\", F.when(F.col(\"Parch\")==0, F.array(F.lit(\"666\"), F.lit(\"777\"))))\n",
    "\n",
    "\n",
    "    # Write a function, add a column, if Parch_New=666 then \"first\" otherwise \"second\"\n",
    "\n",
    "    # Dictionary Loop to recast DataTypes\n",
    "    column_types = {\n",
    "        \"StringType()\": [\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"],\n",
    "        \"IntegerType()\": [\"Pclass\", \"Age\", \"SibSp\", \"Parch\"],\n",
    "        \"BooleanTyp0()\": [\"Survived\"]\n",
    "        }\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column in column_types.items():\n",
    "            df = df.withColumn(\"item\", df.item.cast(\"key\"))\n",
    "\n",
    "    \"\"\"\n",
    "        for key, value in age_group.items():\n",
    "        if df.Age in value:\n",
    "            df = df[key] \n",
    "    \"\"\"\n",
    "\n",
    "    #df = df.withColumn(\"Survived\", df.Survived.cast(BooleanType()))\n",
    "    #df = df.withColumn(\"Sex\", df.Sex.cast(StringType()))\n",
    "    #df = df.withColumn(\"Age\", df.Age.cast(IntegerType()))\n",
    "\n",
    "\n",
    "\n",
    "    # Write a loop that recasts the column types\n",
    "    string_typo = [\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "    if string_typo in df.columns:\n",
    "        for i in string_typo:\n",
    "            df = df.withColumn(i, df.i.cast(\"String\"))    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # A gender selector implemented as a function\n",
    "    # df = genderselector(dataframe=df, selector=\"MALE\")\n",
    "    return df\n",
    " \n",
    "\n",
    "    # This renames the columns\n",
    "    for name in df.columns:\n",
    "        if prefix not in df.columns:\n",
    "            df = df.withColumnRenamed(name, name + '_' + prefix)\n",
    "        else:\n",
    "            raise ValueError('The chosen prefix already appers in the dataframe.')\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "new_df = return_function(titanic, \"Y\", \"MALE\")\n",
    "new_df.show(truncate=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+----------------+\n",
      "|Survived|Pclass|   Sex| Age|Parch|          Ticket|             Fare|Cabin|Embarked|    Class| Parch_New|          CONCAT|\n",
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+----------------+\n",
      "|       0|     3|  MALE|22.0|    0|       A/5 21171|            725.0|  nan|       S|     Prol|[666, 777]|       MALE Prol|\n",
      "|       1|     1|FEMALE|38.0|    0|        PC 17599|          7128.33|  C85|       C| Burgeous|[666, 777]| FEMALE Burgeous|\n",
      "|       1|     3|FEMALE|26.0|    0|STON/O2. 3101282|            792.5|  nan|       S|     Prol|[666, 777]|     FEMALE Prol|\n",
      "|       1|     1|FEMALE|35.0|    0|          113803|           5310.0| C123|       S| Burgeous|[666, 777]| FEMALE Burgeous|\n",
      "|       0|     3|  MALE|35.0|    0|          373450|805.0000000000001|  nan|       S|     Prol|[666, 777]|       MALE Prol|\n",
      "|       0|     3|  MALE| NaN|    0|          330877|845.8299999999999|  nan|       Q|     Prol|[666, 777]|       MALE Prol|\n",
      "|       0|     1|  MALE|54.0|    0|           17463|          5186.25|  E46|       S| Burgeous|[666, 777]|   MALE Burgeous|\n",
      "|       0|     3|  MALE| 2.0|    1|          349909|           2107.5|  nan|       S|     Prol|      null|       MALE Prol|\n",
      "|       1|     3|FEMALE|27.0|    2|          347742|          1113.33|  nan|       S|     Prol|      null|     FEMALE Prol|\n",
      "|       1|     2|FEMALE|14.0|    0|          237736|          3007.08|  nan|       C|Ambitious|[666, 777]|FEMALE Ambitious|\n",
      "|       1|     3|FEMALE| 4.0|    1|         PP 9549|           1670.0|   G6|       S|     Prol|      null|     FEMALE Prol|\n",
      "|       1|     1|FEMALE|58.0|    0|          113783|           2655.0| C103|       S| Burgeous|[666, 777]| FEMALE Burgeous|\n",
      "|       0|     3|  MALE|20.0|    0|       A/5. 2151|805.0000000000001|  nan|       S|     Prol|[666, 777]|       MALE Prol|\n",
      "|       0|     3|  MALE|39.0|    5|          347082|           3127.5|  nan|       S|     Prol|      null|       MALE Prol|\n",
      "|       0|     3|FEMALE|14.0|    0|          350406|           785.42|  nan|       S|     Prol|[666, 777]|     FEMALE Prol|\n",
      "|       1|     2|FEMALE|55.0|    0|          248706|           1600.0|  nan|       S|Ambitious|[666, 777]|FEMALE Ambitious|\n",
      "|       0|     3|  MALE| 2.0|    1|          382652|           2912.5|  nan|       Q|     Prol|      null|       MALE Prol|\n",
      "|       1|     2|  MALE| NaN|    0|          244373|           1300.0|  nan|       S|Ambitious|[666, 777]|  MALE Ambitious|\n",
      "|       0|     3|FEMALE|31.0|    0|          345763|           1800.0|  nan|       S|     Prol|[666, 777]|     FEMALE Prol|\n",
      "|       1|     3|FEMALE| NaN|    0|            2649|            722.5|  nan|       C|     Prol|[666, 777]|     FEMALE Prol|\n",
      "+--------+------+------+----+-----+----------------+-----------------+-----+--------+---------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.withColumn(\"CONCAT\", F.concat(new_df.Sex, F.lit(\" \"), new_df.Class).alias(\"CONCAT\"))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+----------+-----------------+-----+--------+-----+----------+-----------+----+\n",
      "|Survived|Pclass|   Sex| Age|Parch|    Ticket|             Fare|Cabin|Embarked|Class| Parch_New|     CONCAT|RANK|\n",
      "+--------+------+------+----+-----+----------+-----------------+-----+--------+-----+----------+-----------+----+\n",
      "|       0|     3|  MALE|19.0|    0|    365222|            675.0|  nan|       Q| Prol|[666, 777]|  MALE Prol|   1|\n",
      "|       0|     3|FEMALE|18.0|    0|    365226|            675.0|  nan|       Q| Prol|[666, 777]|FEMALE Prol|   1|\n",
      "|       0|     3|  MALE| NaN|    0|    394140|685.8299999999999|  nan|       Q| Prol|[666, 777]|  MALE Prol|   3|\n",
      "|       0|     3|  MALE| NaN|    0|    368323|            695.0|  nan|       Q| Prol|[666, 777]|  MALE Prol|   4|\n",
      "|       0|     3|FEMALE| NaN|    0|    330909|           762.92|  nan|       Q| Prol|[666, 777]|FEMALE Prol|   5|\n",
      "|       0|     3|  MALE| NaN|    0|     36209|            772.5|  nan|       Q| Prol|[666, 777]|  MALE Prol|   6|\n",
      "|       0|     3|  MALE| NaN|    0|    367655|           772.92|  nan|       Q| Prol|[666, 777]|  MALE Prol|   7|\n",
      "|       1|     3|FEMALE|16.0|    0|     35851|773.3299999999999|  nan|       Q| Prol|[666, 777]|FEMALE Prol|   8|\n",
      "|       0|     3|  MALE|21.0|    0|A/5. 13032|773.3299999999999|  nan|       Q| Prol|[666, 777]|  MALE Prol|   8|\n",
      "|       0|     3|  MALE| NaN|    0|    334912|773.3299999999999|  nan|       Q| Prol|[666, 777]|  MALE Prol|   8|\n",
      "|       1|     3|FEMALE| NaN|    0|     35852|773.3299999999999|  nan|       Q| Prol|[666, 777]|FEMALE Prol|   8|\n",
      "|       1|     3|FEMALE| NaN|    0|     36866|           773.75|  nan|       Q| Prol|[666, 777]|FEMALE Prol|  12|\n",
      "|       0|     3|  MALE| NaN|    0|     36865|           773.75|  nan|       Q| Prol|[666, 777]|  MALE Prol|  12|\n",
      "|       0|     3|  MALE|25.0|    0|     36864|           774.17|  nan|       Q| Prol|[666, 777]|  MALE Prol|  14|\n",
      "|       1|     3|FEMALE| NaN|    0|    335677|            775.0|  nan|       Q| Prol|[666, 777]|FEMALE Prol|  15|\n",
      "|       1|     3|FEMALE| NaN|    0|     14311|            775.0|  nan|       Q| Prol|[666, 777]|FEMALE Prol|  15|\n",
      "|       0|     3|  MALE|70.5|    0|    370369|            775.0|  nan|       Q| Prol|[666, 777]|  MALE Prol|  15|\n",
      "|       0|     3|  MALE| NaN|    0|    370372|            775.0|  nan|       Q| Prol|[666, 777]|  MALE Prol|  15|\n",
      "|       0|     3|  MALE| NaN|    0|    368703|            775.0|  nan|       Q| Prol|[666, 777]|  MALE Prol|  15|\n",
      "|       1|     3|FEMALE| NaN|    0|    370370|            775.0|  nan|       Q| Prol|[666, 777]|FEMALE Prol|  15|\n",
      "+--------+------+------+----+-----+----------+-----------------+-----+--------+-----+----------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_sep = Window.partitionBy(\"Embarked\").orderBy(\"Fare\")\n",
    "new_df.withColumn(\"RANK\", F.rank().over(window_sep)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+------+-----------------+-----+--------+--------+----------+----+\n",
      "|Survived|Pclass|   Sex| Age|Parch|Ticket|             Fare|Cabin|Embarked|   Class| Parch_New|RANK|\n",
      "+--------+------+------+----+-----+------+-----------------+-----+--------+--------+----------+----+\n",
      "|       0|     1|  MALE|52.0|    1|110413|7965.000000000001|  E67|       S|Burgeous|      null|   1|\n",
      "|       1|     1|FEMALE|30.0|    0|110152|           8650.0|  B77|       S|Burgeous|[666, 777]|   1|\n",
      "|       1|     1|FEMALE|16.0|    0|110152|           8650.0|  B79|       S|Burgeous|[666, 777]|   1|\n",
      "|       1|     1|FEMALE|33.0|    0|110152|           8650.0|  B77|       S|Burgeous|[666, 777]|   1|\n",
      "+--------+------+------+----+-----+------+-----------------+-----+--------+--------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_sep = Window.partitionBy(\"SEX\").orderBy(\"Ticket\")\n",
    "new_df = new_df.withColumn(\"RANK\", F.rank().over(window_sep))\n",
    "new_df.filter(new_df[\"RANK\"]==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+\n",
      "|          Ticket|col|\n",
      "+----------------+---+\n",
      "|       A/5 21171|666|\n",
      "|       A/5 21171|777|\n",
      "|        PC 17599|666|\n",
      "|        PC 17599|777|\n",
      "|STON/O2. 3101282|666|\n",
      "|STON/O2. 3101282|777|\n",
      "|          113803|666|\n",
      "|          113803|777|\n",
      "|          373450|666|\n",
      "|          373450|777|\n",
      "|          330877|666|\n",
      "|          330877|777|\n",
      "|           17463|666|\n",
      "|           17463|777|\n",
      "|          237736|666|\n",
      "|          237736|777|\n",
      "|          113783|666|\n",
      "|          113783|777|\n",
      "|       A/5. 2151|666|\n",
      "|       A/5. 2151|777|\n",
      "+----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.select(new_df.Ticket, F.explode(new_df.Parch_New))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: long (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      " |-- Pclass: long (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: long (nullable = true)\n",
      " |-- Parch: long (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"/Users/largo/Google Drive/DS/Python/5_Importing_Data_1/Data/titanic_sub.csv\", sep=\",\", header=0)\n",
    "titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]] = titanic[['Sex', 'Ticket', \"Cabin\", \"Embarked\"]].astype(str)\n",
    "titanic = titanic.iloc[0:4, :]\n",
    "\n",
    "def return_function(data):\n",
    "    # This does some random stuff\n",
    "    df = data\n",
    "\n",
    "    # Create age buckets\n",
    "    age_group = {\n",
    "        \"young\": range(0,25),\n",
    "        \"middleaged\": range(26,50),\n",
    "        \"old\": range(51,110)\n",
    "        }\n",
    "\n",
    "\n",
    "    for key, value in age_group.items():\n",
    "        if df.Age in value:\n",
    "            df = df[key]\n",
    "    \n",
    "    return df\n",
    "\n",
    "new_df = return_function(titanic)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "table = spark.createDataFrame(data=simpleData, schema=schema)\n",
    "\n",
    "def recasting_function(data):\n",
    "    df = data\n",
    "\n",
    "    column_types = {\n",
    "        \"StringType()\": [\"employee_name\", \"department\"],\n",
    "        \"IntegerType()\": [\"salary\"]\n",
    "        }\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column in column_types.items():\n",
    "            df = df.withColumn(item, df.item.cast(key))\n",
    "    \n",
    "    return df\n",
    "        \n",
    "\n",
    "result = recasting_function(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a sample dataframe\n",
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "table = spark.createDataFrame(data=simpleData, schema=schema)\n",
    "\n",
    "# This is the function which is supposed to change datatypes en bulk\n",
    "def recasting_function(data):\n",
    "    column_types = {\n",
    "        \"string\": [\"employee_name\", \"department\", \"salary\"]\n",
    "        }\n",
    "    for (k, v) in column_types.items():\n",
    "        for c in v:\n",
    "            if c in data.columns:\n",
    "                data = data.withColumn(c, data[c].cast(k))    \n",
    "    return data\n",
    "        \n",
    "# Here I apply it to my sample dataset\n",
    "result = recasting_function(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93d105ada02192d0bbdad0d4b7f9e51b851ebd5be727b9bab0a9679568b88653"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('pyspark_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
