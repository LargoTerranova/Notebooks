{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approaches\n",
    "\n",
    "### Software based\n",
    "\n",
    "### Hardware based approaches\n",
    "\n",
    "### Conceptual Approaches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Be contious what framework you are using and try to avoid its weaknesses/take advantage of it strengs (Spark Cluster, Pandas, ...)\n",
    "Pre-filtering data to reduce data size, reduce columns/rows\n",
    "Use optimized fuctions from well known packages\n",
    "Dont loop over datapoints\n",
    "Dont collect data\n",
    "Use the correct data type for a column like string, date, timestamp, ...\n",
    "Find the real bottlenecks and dont optimize yourself to death\n",
    "Persisting a DF when you are sure you will use it over and over (exploratory analysis and ML stuff)\n",
    "Dont assume default settings of a compute engine will be best for you (like cluster size in Spark)\n",
    "Chunking large datasets and processing them piece by piece in order to prevent out of mermory problems\n",
    "If possible, use packages/feameworks that can use multiple cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use explain df to analyze the query and then optimize it\n",
    "stupid_df = (df.filter(col(\"event_name\") != \"finalize\"))\n",
    "stupid_df.explain(True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
